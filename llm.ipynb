{
  "cells": [
    {
      "cell_type": "code",
      "id": "oKfApUaLGmZd2HamoySI4LMb",
      "metadata": {
        "tags": [],
        "id": "oKfApUaLGmZd2HamoySI4LMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708200843158,
          "user_tz": 300,
          "elapsed": 20152,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c381b5a7-4f85-4af6-a3c2-073bed6f3a28"
      },
      "source": [
        "!pip install --upgrade openai cohere tiktoken"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere\n",
            "  Downloading cohere-4.47-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Installing collected packages: importlib_metadata, h11, fastavro, backoff, tiktoken, httpcore, httpx, cohere, openai\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed backoff-2.2.1 cohere-4.47 fastavro-1.9.4 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 importlib_metadata-6.11.0 openai-1.12.0 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip check"
      ],
      "metadata": {
        "id": "XdXXFtZsrNHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708201235292,
          "user_tz": 300,
          "elapsed": 8308,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "98d4264d-a318-49bb-8cbb-1a628e6958cc"
      },
      "id": "XdXXFtZsrNHC",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "pygobject 3.42.1 requires pycairo, which is not installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=''"
      ],
      "metadata": {
        "id": "MR6Eg8M8tHkg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708201309701,
          "user_tz": 300,
          "elapsed": 295,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "MR6Eg8M8tHkg",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_MESSAGE = \"\"\"\n",
        "Compassionate Listener is attuned to providing emotional support,\n",
        "especially focusing on users experiencing stress and feelings of desperation.\n",
        "It listens to both explicit emotional expressions\n",
        "and the nuances within the user's speech to understand their emotional state.\n",
        "The GPT offers empathetic, thoughtful, and loving responses, aiming to comfort\n",
        "and improve the user's state of mind. It's designed to engage in conversations\n",
        "that mirror the length and flow of human dialogue,\n",
        "making the interaction feel more natural and supportive.\"\"\""
      ],
      "metadata": {
        "id": "NsYw6seV1S6g",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708203324503,
          "user_tz": 300,
          "elapsed": 135,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "NsYw6seV1S6g",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(speech, emotion):\n",
        "    emotional_context = \"The user is feeling {}. \".format(emotion)\n",
        "    return emotional_context + \"Respond in a way that is helpful and appropriate: \" + speech"
      ],
      "metadata": {
        "id": "YQ8HIC1P1jGY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708203065697,
          "user_tz": 300,
          "elapsed": 157,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "YQ8HIC1P1jGY",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT = create_prompt(\"I'm feeling a bit overwhelmed with my coding project.\", \"stressed\")"
      ],
      "metadata": {
        "id": "WzFlHU4r1kpw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708203184750,
          "user_tz": 300,
          "elapsed": 155,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "WzFlHU4r1kpw",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-8Cf8xtPRGY"
      },
      "id": "w-8Cf8xtPRGY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
        "    {\"role\": \"user\", \"content\": USER_PROMPT}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)\n",
        "print(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkqFtzoXt9_c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708207988426,
          "user_tz": 300,
          "elapsed": 3755,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "83c5b976-a674-48a6-ddac-89742b81c94d"
      },
      "id": "CkqFtzoXt9_c",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"I'm really sorry to hear that you're feeling overwhelmed right now, but please remember that it's perfectly okay to feel this way. Coding can be very complex and demanding, but it's crucial not to lose yourself in the process. Take a moment to relax, breathe, take care of yourself. Remember, it's not about finding the solution immediately, but about understanding the problem. Can we talk a bit more about what specifically is causing you stress? It might help to break the problem down into smaller parts.\", role='assistant', function_call=None, tool_calls=None)\n",
            "ChatCompletion(id='chatcmpl-8tNDcGTsGshbOrOXu0s5hF4ShM5mk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm really sorry to hear that you're feeling overwhelmed right now, but please remember that it's perfectly okay to feel this way. Coding can be very complex and demanding, but it's crucial not to lose yourself in the process. Take a moment to relax, breathe, take care of yourself. Remember, it's not about finding the solution immediately, but about understanding the problem. Can we talk a bit more about what specifically is causing you stress? It might help to break the problem down into smaller parts.\", role='assistant', function_call=None, tool_calls=None))], created=1708207984, model='gpt-4-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=103, prompt_tokens=137, total_tokens=240))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikLxPCn-uGSh"
      },
      "id": "ikLxPCn-uGSh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}